{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training loop\n",
    "```\n",
    "Initialise model parameters ---> Input data --> create model --> compute loss ---> \n",
    "         |                                                                        | \n",
    "         -----------------<---------- Adjust parameters ---------<----------------- \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Input data\n",
    "2. Create model\n",
    "3. Create loss function\n",
    "4. Create minimiser\n",
    "5. Create a TensorFlow session\n",
    "6. Loop the train operation until convergence criterion\n",
    "7. Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "mnist = load_digits(n_class = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X dim : (360, 64)\n",
      "y length : 360\n",
      "Target example : [0 1 0 1 0 1 0 0 1 1]\n",
      "X train dim : (270, 64)\n",
      "y train length : 270\n",
      "Train target example : [1 0 0 1 0 0 1 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "#initalise variables / model parameters\n",
    "X, y = mnist.data,mnist.target\n",
    "print(f'X dim : {X.shape}')\n",
    "print(f'y length : {len(y)}')\n",
    "print(f'Target example : {y[0:10]}')\n",
    "\n",
    "num_of_features = X.shape[1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, random_state = 56)\n",
    "print(f'X train dim : {X_train.shape}')\n",
    "print(f'y train length : {len(y_train)}')\n",
    "print(f'Train target example : {y_train[0:10]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W = tf.Variable (tf.zeros(shape = [num_of_features, 1]) , dtype=tf.float32,name = 'weights' )\n",
    "b = tf.Variable (0,dtype=tf.float32, name = 'bias')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#define the training loop operations\n",
    "def inference(X):\n",
    "    \"\"\"\n",
    "    compute inference model over data (X) \n",
    "    and return the result\n",
    "    \"\"\"\n",
    "    tmp = tf.matmul(X, W) + b\n",
    "    predicted_y = tf.squeeze(tf.nn.sigmoid(tmp))\n",
    "    \n",
    "    return predicted_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#define a loss function\n",
    "def loss(X,Y, fun = 'mean_square'):\n",
    "    \"\"\"\n",
    "    compute loss over data (X) and expected output (Y)\n",
    "    \"\"\"\n",
    "    Y_predicted = inference(X)\n",
    "    if fun == 'mean_square':\n",
    "        loss =  tf.reduce_sum(tf.squared_difference(Y,Y_predicted))\n",
    "    elif fun == 'cross_entropy':\n",
    "        loss = tf.reduce_sum(tf.nn.sigmoid_cross_entropy_with_logits(Y,Y_predicted))\n",
    "        \n",
    "    return loss        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def inputs():\n",
    "    \"\"\"\n",
    "    read/generate training data X and labels Y\n",
    "    \"\"\"\n",
    "    input_X = tf.placeholder(tf.float32,[None, num_of_features],name = 'input_data')\n",
    "    input_Y = tf.placeholder(dtype=tf.float32,shape=[None],name = 'data_labels')\n",
    "    return input_X,input_Y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(total_loss):\n",
    "    \"\"\"train/adjust model parameters according to total loss\"\"\"\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(total_loss)\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(sess, X,Y):\n",
    "    \"\"\"evaluate the model\"\"\" \n",
    "    y_pred = tf.cast(inference(X),tf.float32)\n",
    "    res = sess.run(tf.reduce_mean(tf.cast(tf.equal(Y,y_pred),tf.float32)))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.7504878640174866\n",
      "train auc: 1.0\n",
      "train accuracy: 0.996296296296\n",
      "test auc: 0.99950617284\n",
      "test accuracy: 0.988888888889\n",
      "====\n",
      "loss 0.02127673104405403\n",
      "train auc: 1.0\n",
      "train accuracy: 1.0\n",
      "test auc: 1.0\n",
      "test accuracy: 0.988888888889\n",
      "====\n",
      "loss 0.01470182090997696\n",
      "train auc: 1.0\n",
      "train accuracy: 1.0\n",
      "test auc: 1.0\n",
      "test accuracy: 0.988888888889\n",
      "====\n",
      "loss 0.011650933884084225\n",
      "train auc: 1.0\n",
      "train accuracy: 1.0\n",
      "test auc: 1.0\n",
      "test accuracy: 0.988888888889\n",
      "====\n",
      "loss 0.009653536602854729\n",
      "train auc: 1.0\n",
      "train accuracy: 1.0\n",
      "test auc: 1.0\n",
      "test accuracy: 0.988888888889\n",
      "====\n",
      "loss 0.00823899731040001\n",
      "train auc: 1.0\n",
      "train accuracy: 1.0\n",
      "test auc: 1.0\n",
      "test accuracy: 0.988888888889\n",
      "====\n",
      "loss 0.007185106631368399\n",
      "train auc: 1.0\n",
      "train accuracy: 1.0\n",
      "test auc: 1.0\n",
      "test accuracy: 0.988888888889\n",
      "====\n",
      "loss 0.0063697295263409615\n",
      "train auc: 1.0\n",
      "train accuracy: 1.0\n",
      "test auc: 1.0\n",
      "test accuracy: 0.988888888889\n",
      "====\n",
      "loss 0.005720335058867931\n",
      "train auc: 1.0\n",
      "train accuracy: 1.0\n",
      "test auc: 1.0\n",
      "test accuracy: 0.988888888889\n",
      "====\n",
      "loss 0.005190991796553135\n",
      "train auc: 1.0\n",
      "train accuracy: 1.0\n",
      "test auc: 1.0\n",
      "test accuracy: 0.988888888889\n",
      "====\n"
     ]
    }
   ],
   "source": [
    "#tf.reset_default_graph()\n",
    "saver = tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    model_variables = tf.global_variables_initializer() \n",
    "    sess.run(model_variables)\n",
    "    #tf.global_variables_initializer().run()\n",
    "    \n",
    "    X,Y = inputs()\n",
    "    total_loss = loss(X,Y)\n",
    "    train_op = train(total_loss)\n",
    "    \n",
    "    ###########################\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(sess=sess, coord = coord)\n",
    "    ###########################\n",
    "    num_of_steps = 100\n",
    "    \n",
    "    pred_y = inference(X)\n",
    "    \n",
    "    for step in range(num_of_steps):\n",
    "        sess.run(train_op,{X: X_train, Y: y_train})\n",
    "        if step%10==0:\n",
    "            print (\"loss {}\".format(sess.run(total_loss,{X: X_train, Y: y_train})))\n",
    "            print(\"train auc:\", roc_auc_score(y_train, sess.run(pred_y, {X:X_train})))\n",
    "            print(\"train accuracy:\", accuracy_score(y_train, sess.run(pred_y, {X:X_train}).round()))\n",
    "            print(\"test auc:\", roc_auc_score(y_test, sess.run(pred_y, {X:X_test})))\n",
    "            print(\"test accuracy:\", accuracy_score(y_test, sess.run(pred_y, {X:X_test}).round()),end='\\n====\\n')\n",
    "            #loss reduces as it compares probabilities, while accuracy remains the same.\n",
    "            saver.save(sess,'model',global_step = step)\n",
    "            \n",
    "            \n",
    "    coord.request_stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
